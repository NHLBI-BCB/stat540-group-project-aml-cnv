Random forest analysis
========================================================

Load the data and metadata. In this analysis, I will be using the cleaned RPKM data.

Load libraries:
```{r message=FALSE}
library(kernlab)
library(cvTools)
library(plyr)
library(randomForest)
library(edgeR)
library(limma)
library(VennDiagram)
library(xtable)
```

```{r}
rDes <- read.delim("../../data/experimental_design_cleaned.txt")
rownames(rDes) <- rDes$TCGA_patient_id
rDat <- read.delim("../../data/aml.rnaseq.gaf2.0_rpkm_cleaned.txt", row.names = 1, check.names = FALSE)

all.results <- list()
```


## 1) Functions for feature selection and cross-validation
```{r}
# Function to select features, takes the top 25 differentially expressed genes as determined with limma
# input.dat: training data set
# input.labels: true outcomes for training data
fs.lm <- function(input.dat, input.labels) {
  norm.factor <- calcNormFactors(input.dat)
  design <- model.matrix(~input.labels)
  colnames(design) <- c("Intercept", "Label")
  dat.voomed <- voom(input.dat, design, lib.size = colSums(input.dat) * norm.factor)
  fit <- lmFit(dat.voomed, design)
  ebFit <- eBayes(fit)
  hits <- topTable(ebFit, n = Inf, coef = "Label")
  #train.features <- hits$ID[1:25] FOR OLDER VERSION OF R
  train.features <- rownames(hits)[1:25]
  return(train.features)
}
```


```{r}
# Function to choose features by selecting genes whose expression have the highest correlations to the outcomes (top 25)
# input.dat: training data set
# input.levels: true outcome levels for training data
fs.corr <- function(input.dat, input.levels) {
  gene.corrs <- apply(input.dat, 1, function(x) return(suppressWarnings(cor(x, as.numeric(input.levels), method = "spearman"))))
  gene.corrs <- gene.corrs[order(abs(gene.corrs), na.last = NA, decreasing = TRUE)]
  return(names(gene.corrs[1:25]))
}
```

```{r}
# Function to create a roc curve for a classifier
# votes.mat: matrix of the probabilities assigned to each sample
# true.labels: the true outcomes for the input samples
# plot: whether or not to draw the ROC curve
plot.roc <- function(votes.mat, true.labels) {
  tprs <- c()
	fprs <- c()
	for (i in seq(0, 99.9, by = 0.1)) {
		roc.classification <- vector(length = nrow(votes.mat))
		for (j in 1:nrow(votes.mat)) {
		  if (votes.mat[j, "prob0"] >= (i/100)) {
				roc.classification[j] <- 0
			}
			else {
				roc.classification[j] <- 1
			}
		}
		roc.results <- table(
			factor(true.labels, levels = c(0,1)),
			factor(roc.classification, levels = c(0,1)),
			dnn = c("obs", "pred")
		)
		tprs <- c(tprs, roc.results[2,2] / sum(roc.results[2,]))
		fprs <- c(fprs, roc.results[1,2] / sum(roc.results[1,]))
	}

	roc.data <- data.frame(
		Cutoff = seq(0, 99.9, by = 0.1),
		TPR = tprs,
		FPR = fprs
	)
  roc.data <- rbind(roc.data, c(100, 1, 1))
	auc <- 0
	for (n in 1:(nrow(roc.data) - 1)) {
		auc <- auc + ((roc.data$FPR[n+1] - roc.data$FPR[n]) * roc.data$TPR[n])
	}

  roc.obj <- xyplot(
    TPR ~ FPR,
    roc.data,
    panel = function(...) {
      panel.abline(h = c(0,1), v = c(0,1), col = "darkgrey")
      panel.xyplot(...)
    },
    type = c("s"),
    col = "black",
    xlab = list("1 - Specificity", cex = 1.5),
    ylab = list("Sensitivity", cex = 1.5),
  	key = list(
      x = 0.6,
      y = 0.2,
		  text = list(paste("AUC =", format(auc, digits = 3)), cex = 1.5)
		),
    scales = list(
      x = list(cex = 1.5, limits = c(-0.1, 1.1)),
      y = list(cex = 1.5, limits = c(-0.1, 1.1))
    )
  )
  print(roc.obj)
  
  return(auc)
}
```

```{r}
# Function to run k-fold cross validation with a random forest classifier
# all.dat: all data used in the analysis
# all.labels: true outcomes for the data
# all.levels: true outcome levels for training data
# K: number of folds to use in CV
# fs.method: the strategy to use for feature selection
# plot.varimp: whether to plot the variable importance for each of the trained forests
rf.cv <- function(all.dat, all.labels, all.levels, K = 5, fs.method = "lm", plot.varimp = TRUE) {
  set.seed(540)
  folds <- cvFolds(ncol(all.dat), K = K)

  conf_matrix <- matrix(0, nrow = 2, ncol = 2, dimnames = list(c("true0", "true1"), c("pred0", "pred1")))
  feature.list <- list()
  all.votes <- data.frame(
    sample = colnames(all.dat),
    votes0 = rep(0, ncol(all.dat)),
    votes1 = rep(0, ncol(all.dat)),
    stringsAsFactors = FALSE
  )
  rownames(all.votes) <- colnames(all.dat)
  
  for (f in 1:K) {
    train.samples <- folds$subsets[folds$which != f,]
    test.samples <- folds$subsets[folds$which == f,]
   
    if (fs.method == "lm") {
      train.features <- fs.lm(
        all.dat[,train.samples],
        all.labels[train.samples]
      )
    }
    else if (fs.method == "corr") {
      train.features <- fs.corr(
        all.dat[,train.samples],
        all.levels[train.samples]
      )
    }
    feature.list[[paste("Fold", f, sep = "")]] <- train.features
    
    train.dat <- data.frame(
      class = all.labels[train.samples],
      t(all.dat[train.features, train.samples])
    )
    test.dat <- data.frame(
      t(all.dat[train.features, test.samples])
    )
    test.labels <- all.labels[test.samples]
    
    fit.rf <- randomForest(class ~ ., train.dat)
    if (plot.varimp) { varImpPlot(fit.rf) }
    
    pred.rf <- predict(fit.rf, newdata = test.dat, type = "response")
    results <- table(
      factor(test.labels, levels = c(0,1)),
      factor(pred.rf, levels = c(0,1)),
      dnn = c("obs", "pred")
    )

    conf_matrix[1,1] <- conf_matrix[1,1] + results[1,1]
    conf_matrix[1,2] <- conf_matrix[1,2] + results[1,2]
    conf_matrix[2,1] <- conf_matrix[2,1] + results[2,1]
    conf_matrix[2,2] <- conf_matrix[2,2] + results[2,2]
    
    votes.rf <- predict(fit.rf, newdata = test.dat, type = "prob")
    all.votes[rownames(test.dat), "prob0"] <- as.numeric(votes.rf[,1])
    all.votes[rownames(test.dat), "prob1"] <- as.numeric(votes.rf[,2])
  }
  
  rf.auc <- plot.roc(all.votes, all.labels)
  
  rf.sens <- conf_matrix[2,2] / sum(conf_matrix[2,])
  rf.spec <- conf_matrix[1,1] / sum(conf_matrix[1,])
  rf.acc <- (conf_matrix[1,1] + conf_matrix[2,2]) / sum(conf_matrix)
  
  return(list(acc = rf.acc, sens = rf.sens, spec = rf.spec, auc = rf.auc, feature.list = feature.list))
}
```

```{r}
# Function to analyse a list of selected features by drawing a venn diagram and finding the overlaps
# fts: list of length 5 containing the features selected in each training set
# draw: whether to draw a venn diagram  
# filename: file where venn diagram should be printed (default NA means not saved to file)
summarize.cv.fts <- function(fts, draw = TRUE, filename = NA) {
  venn.plot <- venn.diagram(fts, filename = NULL, fill = c("red", "blue", "green", "yellow", "purple"), margin = 0.1)
  
  if (draw) {
    plot.new()
    grid.draw(venn.plot)
  }  
  if (!is.na(filename)) {
    pdf(filename)
    grid.draw(venn.plot)
    dev.off()
  }

  common.fts <- intersect(fts[[1]], intersect(fts[[2]], intersect(fts[[3]], intersect(fts[[4]], fts[[5]]))))
  return(common.fts)
}
```


## 2) Train RF to predict "Poor" cytogenetic risk, use linear models for feature selection

Set up the data. Remove samples where the cytogenetic risk category is not determined, and set outcomes to poor vs. not poor:
```{r}
rfDes <- rDes[rDes$Cytogenetic_risk != "N.D.",]
rf.labels.poor <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(0,0,1), warn_missing = TRUE)
rf.labels.poor <- factor(rf.labels.poor, levels = c(0,1))
rf.levels <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(3,2,1), warn_missing = TRUE)
rf.levels <- factor(rf.levels)
rfDat <- rDat[,rownames(rfDes)]
```

Run a 5-fold cross-validation for the data:
```{r}
cv.lm.poor <- rf.cv(rfDat, rf.labels.poor, rf.levels, K = 5, fs.method = "lm")
cv.lm.poor[1:4]
all.results[["lm.poor"]] <- cv.lm.poor[1:4]
(common.fts.lm.poor <- summarize.cv.fts(cv.lm.poor[[5]]))
```


## 3) Predict "poor" cytogenetic risk, this time using correlations for feature selection

Run a 5-fold cross-validation for the data:
```{r}
cv.corr.poor <- rf.cv(rfDat, rf.labels.poor, rf.levels, K = 5, fs.method = "corr")
cv.corr.poor[1:4]
all.results[["corr.poor"]] <- cv.corr.poor[1:4]
(common.fts.corr.poor <- summarize.cv.fts(cv.corr.poor[[5]]))
```


## 4) Train RF to predict "Intermediate" cytogenetic risk, use linear models for feature selection

Set up the data. Remove samples where the cytogenetic risk category is not determined, and set categories to intermediate and not intermediate:
```{r}
rfDes <- rDes[rDes$Cytogenetic_risk != "N.D.",]
rf.labels.intermediate <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(0,1,0), warn_missing = TRUE)
rf.labels.intermediate <- factor(rf.labels.intermediate, levels = c(0,1))
rf.levels <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(3,2,1), warn_missing = TRUE)
rf.levels <- factor(rf.levels)
rfDat <- rDat[,rownames(rfDes)]
```

Run a 5-fold cross-validation for the data:
```{r}
cv.lm.intermediate <- rf.cv(rfDat, rf.labels.intermediate, rf.levels, K = 5, fs.method = "lm")
cv.lm.intermediate[1:4]
all.results[["lm.intermediate"]] <- cv.lm.intermediate[1:4]
(common.fts.lm.intermediate <- summarize.cv.fts(cv.lm.intermediate[[5]]))
```


## 5) Train RF to predict "Intermediate" cytogenetic risk, now using correlations for feature selection
```{r}
cv.corr.intermediate <- rf.cv(rfDat, rf.labels.intermediate, rf.levels, K = 5, fs.method = "corr")
cv.corr.intermediate[1:4]
all.results[["corr.intermediate"]] <- cv.corr.intermediate[1:4]
(common.fts.corr.intermediate <- summarize.cv.fts(cv.corr.intermediate[[5]]))
```


## 6) Train RF to predict "Good" cytogenetic risk, use linear models for feature selection

Set up the data. Remove samples where the cytogenetic risk category is not determined, and set categories to good and not good:
```{r}
rfDes <- rDes[rDes$Cytogenetic_risk != "N.D.",]
rf.labels.good <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(1,0,0), warn_missing = TRUE)
rf.labels.good <- factor(rf.labels.good, levels = c(0,1))
rf.levels <- mapvalues(rfDes$Cytogenetic_risk, c("Good","Intermediate","Poor"), c(3,2,1), warn_missing = TRUE)
rf.levels <- factor(rf.levels)
rfDat <- rDat[,rownames(rfDes)]
```

Run a 5-fold cross-validation for the data:
```{r}
cv.lm.good <- rf.cv(rfDat, rf.labels.good, rf.levels, K = 5, fs.method = "lm")
cv.lm.good[1:4]
all.results[["lm.good"]] <- cv.lm.good[1:4]
(common.fts.lm.good <- summarize.cv.fts(cv.lm.good[[5]]))
```


## 7) Train RF to predict "Good" cytogenetic risk, use correlations for feature selection
```{r}
cv.corr.good <- rf.cv(rfDat, rf.labels.good, rf.levels, K = 5, fs.method = "corr")
cv.corr.good[1:4]
all.results[["corr.good"]] <- cv.corr.good[1:4]
(common.fts.corr.good <- summarize.cv.fts(cv.corr.good[[5]]))
```


## 8) Predict the different cytogenetic mutations, use linear models for feature selection

First look at trisomy 8:
```{r}
cv.lm.trisomy8 <- rf.cv(rDat, factor(as.numeric(rDes$trisomy_8)), factor(as.numeric(rDes$trisomy_8)), K = 5, fs.method = "lm")
cv.lm.trisomy8[1:4]
all.results[["lm.trisomy8"]] <- cv.lm.trisomy8[1:4]
(common.fts.lm.trisomy8 <- summarize.cv.fts(cv.lm.trisomy8[[5]]))
```

Next look at deletions of chromosome 5:
```{r}
cv.lm.del5 <- rf.cv(rDat, factor(as.numeric(rDes$del_5)), factor(as.numeric(rDes$del_5)), K = 5, fs.method = "lm")
cv.lm.del5[1:4]
all.results[["lm.del5"]] <- cv.lm.del5[1:4]
(common.fts.lm.del5 <- summarize.cv.fts(cv.lm.del5[[5]]))
```

Next look at deletions of chromosome 7:
```{r}
cv.lm.del7 <- rf.cv(rDat, factor(as.numeric(rDes$del_7)), factor(as.numeric(rDes$del_7)), K = 5, fs.method = "lm")
cv.lm.del7[1:4]
all.results[["lm.del7"]] <- cv.lm.del7[1:4]
(common.fts.lm.del7 <- summarize.cv.fts(cv.lm.del7[[5]]))
```


## 9) Predict the different cytogenetic mutations, now using correlations for feature selection

First look at trisomy 8:
```{r}
cv.corr.trisomy8 <- rf.cv(rDat, factor(as.numeric(rDes$trisomy_8)), factor(as.numeric(rDes$trisomy_8)), K = 5, fs.method = "corr")
cv.corr.trisomy8[1:4]
all.results[["corr.trisomy8"]] <- cv.corr.trisomy8[1:4]
(common.fts.corr.trisomy8 <- summarize.cv.fts(cv.corr.trisomy8[[5]]))
```

Next look at deletions of chromosome 5:
```{r}
cv.corr.del5 <- rf.cv(rDat, factor(as.numeric(rDes$del_5)), factor(as.numeric(rDes$del_5)), K = 5, fs.method = "corr")
cv.corr.del5[1:4]
all.results[["corr.del5"]] <- cv.corr.del5[1:4]
(common.fts.corr.del5 <- summarize.cv.fts(cv.corr.del5[[5]]))
```

Next look at deletions of chromosome 7:
```{r}
cv.corr.del7 <- rf.cv(rDat, factor(as.numeric(rDes$del_7)), factor(as.numeric(rDes$del_7)), K = 5, fs.method = "corr")
cv.corr.del7[1:4]
all.results[["corr.del7"]] <- cv.corr.del7[1:4]
(common.fts.corr.del7 <- summarize.cv.fts(cv.corr.del7[[5]]))
```


## 10) Compare features between outcomes
Compare some of the significant gene lists between classifiers (just considering linear model feature selection).

Compare the three different levels of cytogenetic risk:
```{r}
cyto.all <- list(poor = common.fts.lm.poor, intermediate = common.fts.lm.intermediate, good = common.fts.lm.good)
venn.plot <- venn.diagram(cyto.all, filename = NULL, fill = c("red", "yellow", "blue"))
plot.new()
grid.draw(venn.plot)
```

Look at poor risk vs. the 3 CNAs:
```{r}
fts.all <- list(poor = common.fts.lm.poor, trisomy8 = common.fts.lm.trisomy8, del5 = common.fts.lm.del5, del7 = common.fts.lm.del7)
venn.plot <- venn.diagram(fts.all, filename = NULL, fill = c("red", "yellow", "blue", "green"))
plot.new()
grid.draw(venn.plot)
```

Look at intermediate risk vs. the 3 CNAs:
```{r}
fts.all <- list(intermediate = common.fts.lm.intermediate, trisomy8 = common.fts.lm.trisomy8, del5 = common.fts.lm.del5, del7 = common.fts.lm.del7)
venn.plot <- venn.diagram(fts.all, filename = NULL, fill = c("red", "yellow", "blue", "green"))
plot.new()
grid.draw(venn.plot)
```

Look at good risk vs. the 3 CNAs:
```{r}
fts.all <- list(good = common.fts.lm.good, trisomy8 = common.fts.lm.trisomy8, del5 = common.fts.lm.del5, del7 = common.fts.lm.del7)
venn.plot <- venn.diagram(fts.all, filename = NULL, fill = c("red", "yellow", "blue", "green"))
plot.new()
grid.draw(venn.plot)
```


## 11) Summarize results for all classifiers
```{r results='asis'}
all.results.df <- data.frame(matrix(unlist(all.results), ncol = 4, byrow = TRUE))
rownames(all.results.df) <- names(all.results)
colnames(all.results.df) <- c("accuracy", "sensitivity", "specificity", "auc")
all.results.xt <- xtable(all.results.df)
print(all.results.xt, type = "html")
```